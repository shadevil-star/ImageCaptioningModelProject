{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:44:11.161306Z",
     "iopub.status.busy": "2025-03-15T18:44:11.160965Z",
     "iopub.status.idle": "2025-03-15T18:44:11.180760Z",
     "shell.execute_reply": "2025-03-15T18:44:11.179510Z",
     "shell.execute_reply.started": "2025-03-15T18:44:11.161274Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "### I've used the ResNet50 model for image feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:44:11.183868Z",
     "iopub.status.busy": "2025-03-15T18:44:11.183483Z",
     "iopub.status.idle": "2025-03-15T18:44:11.363139Z",
     "shell.execute_reply": "2025-03-15T18:44:11.361915Z",
     "shell.execute_reply.started": "2025-03-15T18:44:11.183836Z"
    }
   },
   "outputs": [],
   "source": [
    "### After extracting the features and I had dumped the image_feature_map in my PC's storage\n",
    "with open('/kaggle/input/idksomethingsomething11111/image_features.pkl', 'rb') as f:\n",
    "    features = pickle.load(f)\n",
    "\n",
    "### After fixing the given captions I dumped them in my PC's storage\n",
    "with open('/kaggle/input/idksomethingsomething11111/caption_map.pkl', 'rb') as f:\n",
    "    captions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "image_features_map = {}\n",
    "\n",
    "\n",
    "def extract_features(image_path, model):\n",
    "    img = load_img(image_path, target_size=(224, 224))  # Resize to match ResNet50 input\n",
    "    img = img_to_array(img)  # Convert to numpy array\n",
    "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))  \n",
    "    img = preprocess_input(img) \n",
    "    features = model.predict(img)  \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "folder_path = \"C:/Users/User/Music/archive (1)/Images\"\n",
    "for name in os.listdir(folder_path):\n",
    "    ##image_path = os.path.join(folder_path, name)\n",
    "    \n",
    "    name = name.split('.')[0]\n",
    "    image_features_map[name] = extract_features(image_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "new_caption_map = {}\n",
    "for keys in caption_map:\n",
    "    lsst = [] \n",
    "    for sentence in caption_map[keys]:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(r'[^a-z\\s]', '', sentence)  \n",
    "        sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
    "        sentence = 'startseq ' + \" \".join([word for word in sentence.split() if len(word) > 1]) + ' endseq'\n",
    "        lsst.append(sentence)\n",
    "    \n",
    "    new_caption_map[keys] = lsst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:44:11.365635Z",
     "iopub.status.busy": "2025-03-15T18:44:11.365286Z",
     "iopub.status.idle": "2025-03-15T18:44:11.375616Z",
     "shell.execute_reply": "2025-03-15T18:44:11.374442Z",
     "shell.execute_reply.started": "2025-03-15T18:44:11.365605Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
    "    while 1:\n",
    "        # Shuffle data keys at the start of each epoch\n",
    "        random.shuffle(data_keys)\n",
    "        X1, X2, y = list(), list(), list()\n",
    "        n = 0\n",
    "\n",
    "        for key in data_keys:\n",
    "            captions = mapping[key]\n",
    "            # Shuffle captions if needed\n",
    "            random.shuffle(captions)\n",
    "\n",
    "            # Process each caption\n",
    "            for caption in captions:\n",
    "                # Encode the sequence\n",
    "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "                # Split the sequence into X, y pairs\n",
    "                for i in range(1, len(seq)):\n",
    "\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length, padding='post')[0]\n",
    "                    # Encode output sequence\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                    X1.append(features[key][0])\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "\n",
    "            n += 1\n",
    "            if n == batch_size:\n",
    "                indices = list(range(len(X1)))\n",
    "                random.shuffle(indices)\n",
    "                X1 = np.array([X1[i] for i in indices])\n",
    "                X2 = np.array([X2[i] for i in indices])\n",
    "                y = np.array([y[i] for i in indices])\n",
    "\n",
    "                yield {\"image\": X1, \"text\": X2}, y\n",
    "\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:44:11.377449Z",
     "iopub.status.busy": "2025-03-15T18:44:11.376995Z",
     "iopub.status.idle": "2025-03-15T18:44:11.406957Z",
     "shell.execute_reply": "2025-03-15T18:44:11.405599Z",
     "shell.execute_reply.started": "2025-03-15T18:44:11.377403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_features = {}\n",
    "count = 1\n",
    "\n",
    "for i in range(1,5601):\n",
    "    train_img_features[f'img{i}'] = features[f'img{i}']\n",
    "\n",
    "len(train_img_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:44:11.408454Z",
     "iopub.status.busy": "2025-03-15T18:44:11.408165Z",
     "iopub.status.idle": "2025-03-15T18:44:11.436183Z",
     "shell.execute_reply": "2025-03-15T18:44:11.434988Z",
     "shell.execute_reply.started": "2025-03-15T18:44:11.408430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8091"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_captions = {}\n",
    "for key in captions:\n",
    "    new_key = key.split('.')[0]\n",
    "    new_captions[new_key] = captions[key]\n",
    "\n",
    "\n",
    "len(new_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:44:11.437772Z",
     "iopub.status.busy": "2025-03-15T18:44:11.437441Z",
     "iopub.status.idle": "2025-03-15T18:44:11.466468Z",
     "shell.execute_reply": "2025-03-15T18:44:11.465289Z",
     "shell.execute_reply.started": "2025-03-15T18:44:11.437743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captions = {}\n",
    "count = 1\n",
    "\n",
    "for i in range(1,5601):\n",
    "    train_captions[f'img{i}'] = new_captions[f'img{i}']\n",
    "\n",
    "len(train_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:44:11.468107Z",
     "iopub.status.busy": "2025-03-15T18:44:11.467750Z",
     "iopub.status.idle": "2025-03-15T18:44:11.501639Z",
     "shell.execute_reply": "2025-03-15T18:44:11.500675Z",
     "shell.execute_reply.started": "2025-03-15T18:44:11.468071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40455"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_captions = []\n",
    "for key in captions:\n",
    "    for val in captions[key]:\n",
    "        all_captions.append(val)\n",
    "\n",
    "len(all_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:44:11.503068Z",
     "iopub.status.busy": "2025-03-15T18:44:11.502658Z",
     "iopub.status.idle": "2025-03-15T18:44:12.165245Z",
     "shell.execute_reply": "2025-03-15T18:44:12.164135Z",
     "shell.execute_reply.started": "2025-03-15T18:44:11.503008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size of the Tokenizer is : 8313 & the Max Length is : 31\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max(len(caption.split()) for caption in all_captions)\n",
    "print(f'Vocabulary Size of the Tokenizer is : {vocab_size} & the Max Length is : {max_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T15:38:29.761787Z",
     "iopub.status.busy": "2025-03-15T15:38:29.761292Z",
     "iopub.status.idle": "2025-03-15T15:38:29.769972Z",
     "shell.execute_reply": "2025-03-15T15:38:29.768920Z",
     "shell.execute_reply.started": "2025-03-15T15:38:29.761758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14186075, 0.49956983, 0.29384995, ..., 0.13239394, 0.52375025,\n",
       "        0.24152865]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['img6000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T19:04:24.492649Z",
     "iopub.status.busy": "2025-03-15T19:04:24.492224Z",
     "iopub.status.idle": "2025-03-15T19:04:24.499986Z",
     "shell.execute_reply": "2025-03-15T19:04:24.498735Z",
     "shell.execute_reply.started": "2025-03-15T19:04:24.492610Z"
    }
   },
   "outputs": [],
   "source": [
    "def idx_to_word(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "def predict_caption(model, image, tokenizer, max_length):\n",
    "    # add start tag for generation process\n",
    "    in_text = 'startseq'\n",
    "    # iterate over the max length of sequence\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], max_length, padding='post')\n",
    "        yhat = model.predict([image, sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = idx_to_word(yhat, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += \" \" + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T18:14:59.147852Z",
     "iopub.status.busy": "2025-03-15T18:14:59.147369Z",
     "iopub.status.idle": "2025-03-15T18:20:40.110579Z",
     "shell.execute_reply": "2025-03-15T18:20:40.109364Z",
     "shell.execute_reply.started": "2025-03-15T18:14:59.147814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,128,128</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                           │                        │                │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                           │                        │                │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8313</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,136,441</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │      \u001b[38;5;34m2,128,128\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m524,544\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m525,312\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                           │                        │                │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                           │                        │                │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m65,792\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8313\u001b[0m)           │      \u001b[38;5;34m2,136,441\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,380,217</span> (20.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,380,217\u001b[0m (20.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,380,217</span> (20.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,380,217\u001b[0m (20.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 128ms/step - loss: 6.5987\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 127ms/step - loss: 4.9738\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 127ms/step - loss: 4.5494\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 127ms/step - loss: 4.1094\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 130ms/step - loss: 3.7569\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 128ms/step - loss: 3.4717\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 127ms/step - loss: 3.1963\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 129ms/step - loss: 2.9846\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 128ms/step - loss: 2.7613\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - loss: 2.6088\n"
     ]
    }
   ],
   "source": [
    "model = define_model(vocab_size, max_length)\n",
    "\n",
    "epochs = 10\n",
    "steps = len(train_captions)\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(train_captions, train_img_features, tokenizer, max_length, vocab_size)\n",
    "    model.fit(generator, epochs=1, steps_per_epoch=250, verbose=1)\n",
    "    model.save('model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T19:09:07.263821Z",
     "iopub.status.busy": "2025-03-15T19:09:07.263412Z",
     "iopub.status.idle": "2025-03-15T19:09:07.819214Z",
     "shell.execute_reply": "2025-03-15T19:09:07.818015Z",
     "shell.execute_reply.started": "2025-03-15T19:09:07.263788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'startseq man is sitting on the street endseq'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_caption(model, features['img1513'], tokenizer, max_length)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T19:14:20.015867Z",
     "iopub.status.busy": "2025-03-15T19:14:20.015527Z",
     "iopub.status.idle": "2025-03-15T19:15:30.833784Z",
     "shell.execute_reply": "2025-03-15T19:15:30.832543Z",
     "shell.execute_reply.started": "2025-03-15T19:14:20.015842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db41e9d56c1413aa513cd96a8f65733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/810 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net BLEU-1: 0.659352\n",
      "Net BLEU-2: 0.443801\n",
      "Net BLEU-3: 0.331601\n",
      "Net BLEU-4: 0.177773\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Validate with test data\n",
    "actual, predicted = list(), list()\n",
    "count = 0\n",
    "\n",
    "for key in tqdm(test):\n",
    "    # Get actual captions\n",
    "    captions = new_captions[key]\n",
    "    # Predict the caption for the image\n",
    "    y_pred = predict_caption(model, features[key], tokenizer, max_length)\n",
    "    actual_captions = [caption.split() for caption in captions]\n",
    "    y_pred = y_pred.split()\n",
    "    actual.append(actual_captions)\n",
    "    predicted.append(y_pred)\n",
    "    \n",
    "    # Increment count and break after 100 samples\n",
    "    count += 1\n",
    "    if count == 100:\n",
    "        break\n",
    "\n",
    "# Calculate overall BLEU scores\n",
    "print(\"Net BLEU-1: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "print(\"Net BLEU-2: %f\" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "print(\"Net BLEU-3: %f\" % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "print(\"Net BLEU-4: %f\" % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "\n",
    "\n",
    "### I imported the .ipynb file from Kaggle hence the 0%. I found out the BLEU score of the first 100 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6876914,
     "sourceId": 11040396,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
